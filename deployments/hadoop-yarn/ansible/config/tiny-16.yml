#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

all:

    vars:

        cloudname:  "{{aglais.spec.openstack.cloud}}"
        deployname: "{{aglais.status.deployment.name}}"

        sshkeys: "{{ deployname }}-keypair"

        networks:
            internal: "{{ deployname }}-internal-network"
            external: 'internet'
            cumulus:  'cumulus-internal'

        security:
            gateway:  "{{ deployname }}-gateway-security"
            zeppelin: "{{ deployname }}-zeppelin-security"
            masters:  "{{ deployname }}-master-security"
            workers:  "{{ deployname }}-worker-security"

        ansible_ssh_common_args: "-F {{ lookup('env','HOME') }}/.ssh/ansible-config"

        # https://docs.ansible.com/ansible/2.8/reference_appendices/interpreter_discovery.html
        ansible_interpreter_python: 'auto'

        # https://docs.ansible.com/ansible/latest/user_guide/intro_getting_started.html#host-key-checking
        ansible_host_key_checking: false

    # Hadoop vars

        hdname: "hadoop-3.1.3"
        hdbase: "/opt"
        hdhome: "/opt/hadoop"

        hdconf: "{{hdhome}}/etc/hadoop"
        hdhost: "master01"
        hduser: "fedora"

    # HDFS vars

        hdfsconf: "/var/hdfs/conf"
        hdfsuser: "fedora"

  # Spark vars
        spname: "spark-2.4.7"
        spfull: "spark-2.4.7-bin-hadoop2.7"
        spbase: "/opt"
        sphome: "/opt/spark"
        sphost: "master01"
        spuser: "fedora"

    # Zeppelin vars
        zepname: "zeppelin-0.8.2"
        zepbase: "/home/fedora"
        zephome: "/home/fedora/zeppelin-0.8.2-bin-all"
        zephost: "zeppelin"
        zepuser: "fedora"

    # User accounts and ssh keys.
        users:
            dcr:
                sshkey: 'dmr.roe.ac.uk.rsa.pub'
            dmr:
                sshkey: 'dmr.roe.ac.uk.rsa.pub'
            nch:
                sshkey: 'nch.roe.ac.uk.rsa.pub'
            stv:
                sshkey: 'stv.roe.ac.uk.rsa.pub'
            zrq:
                sshkey: 'zrq.openstack.cam.ac.uk.rsa.pub'

    hosts:

        zeppelin:
            login:  'fedora'
            image:  'Fedora-30-1.2'
            flavor: 'general.v1.medium'
            discs:
              - type: 'local'
                format: 'ext4'
                mntpath: "/mnt/local/vdb"
                devname: 'vdb'
              - type: 'cinder'
                size: 512
                format: 'btrfs'
                mntpath: "/mnt/cinder/vdc"
                devname: 'vdc'
            paths:
                # Empty on Zeppelin, master, worker
                hddatalink: "/var/hadoop/data"
                hddatadest: "/mnt/local/vdb/hadoop/data"
                # Empty on Zeppelin
                hdtemplink: "/var/hadoop/temp"
                hdtempdest: "/mnt/local/vdb/hadoop/temp"
                # Empty on Zeppelin
                hdlogslink: "/var/hadoop/logs"
                hdlogsdest: "/mnt/local/vdb/hadoop/logs"
                # Used on Zeppelin
                sptemplink: "/var/spark/temp"
                sptempdest: "/mnt/cinder/vdc/spark/temp"

    children:

        masters:
            hosts:
                master[01:01]:
            vars:
                login:  'fedora'
                image:  'Fedora-30-1.2'
                flavor: 'general.v1.small'
                paths:
                    # Empty on Zeppelin, master, worker
                    hddatalink: "/var/hadoop/data"
                    hddatadest: "/mnt/local/vda/hadoop/data"
                    # Used on master
                    # /var/hadoop/temp/dfs/namesecondary/current/
                    hdtemplink: "/var/hadoop/temp"
                    hdtempdest: "/mnt/local/vda/hadoop/temp"
                    # Used on master
                    hdlogslink: "/var/hadoop/logs"
                    hdlogsdest: "/mnt/local/vda/hadoop/logs"
                    # Used on master
                    # /var/hdfs/meta/namenode/fsimage/current/
                    hdfsmetalink: "/var/hdfs/meta"
                    hdfsmetadest: "/mnt/local/vda/hadoop/meta"

        workers:
            hosts:
                worker[01:16]:
            vars:
                login:  'fedora'
                image:  'Fedora-30-1.2'
                flavor: 'general.v1.tiny'
                discs:
                  - type: 'cinder'
                    size: 200
                    format: 'btrfs'
                    mntpath: "/mnt/cinder/vdb"
                    devname: 'vdb'
                paths:
                    # Empty on Zeppelin, master, worker
                    hddatalink: "/var/hadoop/data"
                    hddatadest: "/mnt/cinder/vdb/hadoop/data"
                    # Used on workers
                    # /var/hadoop/temp/nm-local-dir/
                    hdtemplink: "/var/hadoop/temp"
                    hdtempdest: "/mnt/cinder/vdb/hadoop/temp"
                    # Used on worker
                    hdlogslink: "/var/hadoop/logs"
                    hdlogsdest: "/mnt/cinder/vdb/hadoop/logs"
                    # Workers only, empty
                    hdfslogslink: "/var/hdfs/logs"
                    hdfslogsdest: "/mnt/local/vdb/hdfs/logs"
                    # Workers only, used
                    hdfsdatalink: "/var/hdfs/data"
                    hdfsdatadest: "/mnt/cinder/vdb/hdfs/data"

