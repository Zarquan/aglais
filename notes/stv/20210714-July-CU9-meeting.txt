#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#


# ------------------------------
# Notes on GAIA CU9 meeting
#  2021-07-14
# ------------------------------



# -----------------------------------------
# Questions from talk by Dave Morris


- Enrique Utrilla

I know that that for the performance how data is stored is critical
Have you partitioned the data by sourceID or by the healpix?

 Healpix ID is probably good for machine learning / visualization.
 If we want join between tables better to partition by source ID

Interested to hear on how we get on with the Kubernetes Deploy


------------------- 


- Alejandro Lorca

Also working on preparing some similar technology solutions
Very interested on trying to isolate users on the back end like DMR presented with the Kuberentes partitioning of users
Are we allowing users to store data, have user space?
Or more of a question of escalating resources?


Dave: 

User space is one of the things we want to do (but not main reason for doing the above)
We are following the Zeppelin v3 K8s deployment where interpreters are deployed as separate containers


--------------------


- Jordi Portell de Mora (in Chat)

Dave, very interesting, thanks! Here in Barcelona we have quite some experience on data partitioning (years ago with Oracle DB...), perhaps we can have a chat one of these days 




# -----------------------------------------
# Enrique Utrilla
# CU9 DAF

JupyterLab interface
80 CPU Cores / session
Limited subset of people using it

- Apache Spark
Better performance if data is converted to Parquet
But can also work on gbins

Programmatic API & SQL API


- Architecture

Hub -> REST/HTTP -> Livy -> Spark Master -> Spark Worker nodes
Apache Livy needed due to security constraints, but has limitations



- Tips

Do not try to do everything with Pandas!

Consider using Koalas instead

%matplot plt to plot static Matplotlib png on the cluster

Working with array columns is possible
  Generate several rows
  Split into columns

They are using Dynamic Allocation


STV: Hi Enrique, I had one more quick question, do you use Yarn or Mesos as a resource manager? 
Enrique: Neither, we are using the standalone resource manager from Spark itself. It's simple and we don't need more for the time being. But it's rather similar to YARN, and probably we will migrate to it at some point in the future. 


Actually I was rather surprised by how easy it was to set up the dynamic allocation. It's just that you have to take into account that it will not handle the case where a job is using the whole cluster and new job arrives, it would just get queued until the first job releases resources. 

But it does cover the case of people opening a notebook, launching a huge query, then going for lunch, and running something else afterwards. The driver process will keep the state (e.g. contents of variables), and the executors will be released after the first query finishes 
