#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#



    Target:

        Test the latest settings for the tiny-16 deployment

    Result:

        Work in progress
        Test pass for 500 tree RandomForest
        Test fail for 1,000 tree RandomForest
            Out of disc space


# -----------------------------------------------------
# Checkout the deployment branch.
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"

            git checkout '20210428-zrq-spark-conf'

    popd


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    AGLAIS_CLOUD=gaia-test

    docker run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        atolmis/ansible-client:2020.12.02 \
        bash


# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}"


     >   Done

# -----------------------------------------------------
# Create everything, using the tiny-16 config.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            'tiny-16'


	TASK [Download and unpack

	TASK [Checking destination [/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE]] ***********************************************************************************************************************************
	task path: /deployments/hadoop-yarn/ansible/tasks/create-linked.yml:39
	ok: [worker01] => {"changed": false, "stat": {"exists": false}}
	ok: [worker02] => {"changed": false, "stat": {"exists": false}}
	ok: [worker03] => {"changed": false, "stat": {"exists": false}}
	ok: [worker04] => {"changed": false, "stat": {"exists": false}}
	ok: [zeppelin] => {"changed": false, "stat": {"exists": false}}
	ok: [worker05] => {"changed": false, "stat": {"exists": false}}
	ok: [worker07] => {"changed": false, "stat": {"exists": false}}
	ok: [worker06] => {"changed": false, "stat": {"exists": false}}
	ok: [worker08] => {"changed": false, "stat": {"exists": false}}
	ok: [worker09] => {"changed": false, "stat": {"exists": false}}
	ok: [worker11] => {"changed": false, "stat": {"exists": false}}
	ok: [worker10] => {"changed": false, "stat": {"exists": false}}
	ok: [worker12] => {"changed": false, "stat": {"exists": false}}
	ok: [worker13] => {"changed": false, "stat": {"exists": false}}
	ok: [worker14] => {"changed": false, "stat": {"exists": false}}
	ok: [worker15] => {"changed": false, "stat": {"exists": false}}
	ok: [worker16] => {"changed": false, "stat": {"exists": false}}

	TASK [Creating destination [/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE]] ***********************************************************************************************************************************
	task path: /deployments/hadoop-yarn/ansible/tasks/create-linked.yml:45
	fatal: [worker02]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker03]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker01]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker04]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [zeppelin]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker05]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker08]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker07]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker06]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker09]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker12]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker13]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker10]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker14]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker11]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker15]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker16]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}

	PLAY RECAP **************************************************************************************************************************************************************************************************
	worker01                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker02                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker03                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker04                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker05                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker06                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker07                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker08                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker09                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker10                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker11                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker12                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker13                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker14                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker15                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker16                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	zeppelin                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   


	real	70m59.313s
	user	20m25.645s
	sys	6m14.355s



# Try again..



# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}"


     >   Done

# -----------------------------------------------------
# Create everything, using the tiny-16 config.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            'tiny-16'


	TASK [Creating destination parent [/data/gaia/GEDR2_6514]] **************************************************************************************************************************************************
	task path: /deployments/hadoop-yarn/ansible/tasks/create-linked.yml:29
	skipping: [zeppelin] => {"changed": false, "skip_reason": "Conditional result was False"}
	skipping: [worker01] => {"changed": false, "skip_reason": "Conditional result was False"}
	skipping: [worker02] => {"changed": false, "skip_reason": "Conditional result was False"}
	skipping: [worker03] => {"changed": false, "skip_reason": "Conditional result was False"}
	skipping: [worker04] => {"changed": false, "skip_reason": "Conditional result was False"}
	skipping: [worker05] => {"changed": false, "skip_reason": "Conditional result was False"}
	skipping: [worker06] => {"changed": false, "skip_reason": "Conditional result was False"}
	skipping: [worker07] => {"changed": false, "skip_reason": "Conditional result was False"}
	skipping: [worker08] => {"changed": false, "skip_reason": "Conditional result was False"}
	skipping: [worker09] => {"changed": false, "skip_reason": "Conditional result was False"}
	skipping: [worker10] => {"changed": false, "skip_reason": "Conditional result was False"}
	skipping: [worker11] => {"changed": false, "skip_reason": "Conditional result was False"}
	skipping: [worker12] => {"changed": false, "skip_reason": "Conditional result was False"}
	skipping: [worker13] => {"changed": false, "skip_reason": "Conditional result was False"}
	skipping: [worker14] => {"changed": false, "skip_reason": "Conditional result was False"}
	skipping: [worker15] => {"changed": false, "skip_reason": "Conditional result was False"}
	skipping: [worker16] => {"changed": false, "skip_reason": "Conditional result was False"}

	TASK [Checking destination [/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE]] ***********************************************************************************************************************************
	task path: /deployments/hadoop-yarn/ansible/tasks/create-linked.yml:39
	ok: [worker02] => {"changed": false, "stat": {"exists": false}}
	ok: [worker01] => {"changed": false, "stat": {"exists": false}}
	ok: [worker04] => {"changed": false, "stat": {"exists": false}}
	ok: [worker03] => {"changed": false, "stat": {"exists": false}}
	ok: [zeppelin] => {"changed": false, "stat": {"exists": false}}
	ok: [worker05] => {"changed": false, "stat": {"exists": false}}
	ok: [worker06] => {"changed": false, "stat": {"exists": false}}
	ok: [worker08] => {"changed": false, "stat": {"exists": false}}
	ok: [worker07] => {"changed": false, "stat": {"exists": false}}
	ok: [worker09] => {"changed": false, "stat": {"exists": false}}
	ok: [worker13] => {"changed": false, "stat": {"exists": false}}
	ok: [worker10] => {"changed": false, "stat": {"exists": false}}
	ok: [worker14] => {"changed": false, "stat": {"exists": false}}
	ok: [worker11] => {"changed": false, "stat": {"exists": false}}
	ok: [worker12] => {"changed": false, "stat": {"exists": false}}
	ok: [worker16] => {"changed": false, "stat": {"exists": false}}
	ok: [worker15] => {"changed": false, "stat": {"exists": false}}

	TASK [Creating destination [/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE]] ***********************************************************************************************************************************
	task path: /deployments/hadoop-yarn/ansible/tasks/create-linked.yml:45
	fatal: [worker02]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker01]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [zeppelin]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker04]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker03]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker07]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker06]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker09]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker08]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker05]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker10]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker11]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker13]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker12]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker14]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker15]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}
	fatal: [worker16]: FAILED! => {"changed": false, "msg": "There was an issue creating /data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE as requested: [Errno 30] Read-only file system: b'/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE'", "path": "/data/gaia/GEDR2_6514/GEDR2_6514_GAIASOURCE"}

	PLAY RECAP **************************************************************************************************************************************************************************************************
	worker01                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker02                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker03                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker04                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker05                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker06                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker07                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker08                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker09                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker10                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker11                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker12                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker13                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker14                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker15                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	worker16                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
	zeppelin                   : ok=12   changed=0    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   


	real	77m8.631s
	user	21m3.364s
	sys	6m30.339s

        # Same error


# -----------------------------------------------------
# Setup integration with github
#[root@ansibler]


  ssh zeppelin \
        '
        export githubuser=user
        export githubpass=pass

        rm -rf /home/fedora/zeppelin-0.8.2-bin-all/notebook
	git clone https://${githubuser:?}:${githubpass:?}@github.com/wfau/aglais-notebooks.git /home/fedora/zeppelin-0.8.2-bin-all/notebook

	cat > "${HOME}/zeppelin-0.8.2-bin-all/notebook/.git/hooks/post-commit" << EOF
	#!/bin/sh
	git push 

	EOF

	chmod +x ${HOME}/zeppelin-0.8.2-bin-all/notebook/.git/hooks/post-commit
	/home/fedora/zeppelin-0.8.2-bin-all/bin/zeppelin-daemon.sh restart
	'

	> Cloning into '/home/fedora/zeppelin-0.8.2-bin-all/notebook'...
	  Zeppelin stop                                              [  OK  ]
	  Zeppelin start                                             [  OK  ]

	# Success



# -----------------------------------------------------
# Login via Firefox
#[user@desktop]

    firefox --new-window "http://128.232.227.137:8080/" &



# -----------------------------------------------------
# Run a set of known Notebooks for validation
# -----------------------------------------------------

 
    # AglaisPublicExamples/Set Up
    # ----------------------------------------------------------
 
    # Change the Catalogue Setup tp:

	%pyspark

	# database name to create
	database = "gaiaedr3"

	# root data store path: TODO change this to the official one when established.
	data_store = "file://///data/gaia/GEDR3_2048/"

	# create the database and switch the current SQL database context to it (from default)
	spark.sql("create database " + database)
	spark.sql("use " + database)

	# create the tables against their corresponding file sets and schema
	reattachParquetFileResourceToSparkContext("gaia_source", data_store + "GEDR3_GAIASOURCE", gaia_source_schema)
	reattachParquetFileResourceToSparkContext("gaia_source_tmasspsc_best_neighbours", data_store + "GEDR3_2048_2MASSPSC_BEST_NEIGHBOURS", tmasspscxsc_best_neighbour_schema, twomass_psc_schema)
	reattachParquetFileResourceToSparkContext("gaia_source_allwise_best_neighbours", data_store + "GEDR3_ALLWISE_BEST_NEIGHBOURS", allwise_best_neighbour_schema, twomass_psc_schema)
        reattachParquetFileResourceToSparkContext("gaia_source_ps1_best_neighbours", data_store + "GEDR3_2MASSPSC_BEST_NEIGHBOURS", panstarrs1_best_neighbour_schema, panstarrs_dr1_otmo_schema)
 
    [Success]


    # AglaisPublicExamples/Data Holdings 
    # ----------------------------------------------------------
 
    [Success]


    # AglaisPublicExamples/5d kinematic clustering 
    # ----------------------------------------------------------
	  %pyspark

	# apply the velocity cut to the data frame and at this point cache for downstream processing
	df_lsr_cut = df.select("*").where("udf_lsr_cut(ra, dec, parallax, pmra, pmdec) = 1").cache()

	# sanity check
	df_lsr_cut.show()
	print ("Data frame rows: ",df_lsr_cut.count())
	# cf. Kounkel & Covey (2019) on DR2: 
	Py4JJavaError: An error occurred while calling o194.count.

: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1180 in stage 9.0 failed 4 times, most recent failure: Lost task 1180.3 in stage 9.0 (TID 2801, worker08, executor 40): java.io.FileNotFoundException: File file:/data/gaia/GEDR3_2048/GEDR3_GAIASOURCE/part-01180-061dbeeb-75b5-41c3-9d01-422766759ddd_01180.c000.snappy.parquet does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:127)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	at org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:346)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:195)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)
	at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2836)
	at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2835)
	at org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3369)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:2835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: File file:/data/gaia/GEDR3_2048/GEDR3_GAIASOURCE/part-01180-061dbeeb-75b5-41c3-9d01-422766759ddd_01180.c000.snappy.parquet does not exist
It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:127)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.scan_nextBatch_0$(Unknown Source)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1124)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	at org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:346)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:195)
    

   #  Parquet file not accessible on worker08

   [fedora@gaia-test-20210521-worker08 ~]$ cat /data/gaia/GEDR3_2048/GEDR3_GAIASOURCE/part-01981-061dbeeb-75b5-41c3-9d01-422766759ddd_01981.c000.snappy.parquet
   cat: /data/gaia/GEDR3_2048/GEDR3_GAIASOURCE/part-01981-061dbeeb-75b5-41c3-9d01-422766759ddd_01981.c000.snappy.parquet: Transport endpoint is not connected

   ls -al /data/gaia/
        ls: cannot access '/data/gaia/GEDR3_2048': Transport endpoint is not connected
	total 10
	drwxr-xr-x. 6 root root         4096 May 21 12:57 .
	drwxr-xr-x. 6 root root         4096 May 21 13:01 ..
	drwxr-xr-x. 3 root root 507579156167 May 19 00:45 GEDR2_6514
	drwxr-xr-x. 3 root root 571353028676 May 14 11:23 GEDR3_11932
	d?????????? ? ?    ?               ?            ? GEDR3_2048
	drwxr-xr-x. 6 root root 603089119750 May 14 12:28 GEDR3_4096
	5:39

    # Following a suggestion from dmr
    sudo umount /data/gaia/GEDR3_2048
    sudo mount /data/gaia/GEDR3_2048 (edited) 

    # Notebooks working again
    
    # ...
 
    # New error (Notebook runs for quite a while, going over 125% completion, then fails with the following exception): 

Py4JJavaError: An error occurred while calling o516.count.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 296 in stage 58.0 failed 4 times, most recent failure: Lost task 296.4 in stage 58.0 (TID 23348, worker13, executor 163): org.apache.spark.SparkException: No port number in pyspark.daemon's stdout
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:204)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:122)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:95)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:109)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:81)
	at org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:127)
	at org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:89)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:359)
	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:357)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:989)
	at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)
	at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2836)
	at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2835)
	at org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3370)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)
	at org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3369)
	at org.apache.spark.sql.Dataset.count(Dataset.scala:2835)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: No port number in pyspark.daemon's stdout
	at org.apache.spark.api.python.PythonWorkerFactory.startDaemon(PythonWorkerFactory.scala:204)
	at org.apache.spark.api.python.PythonWorkerFactory.createThroughDaemon(PythonWorkerFactory.scala:122)
	at org.apache.spark.api.python.PythonWorkerFactory.create(PythonWorkerFactory.scala:95)
	at org.apache.spark.SparkEnv.createPythonWorker(SparkEnv.scala:117)
	at org.apache.spark.api.python.BasePythonRunner.compute(PythonRunner.scala:109)
	at org.apache.spark.sql.execution.python.BatchEvalPythonExec.evaluate(BatchEvalPythonExec.scala:81)
	at org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:127)
	at org.apache.spark.sql.execution.python.EvalPythonExec$$anonfun$doExecute$1.apply(EvalPythonExec.scala:89)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:359)
	at org.apache.spark.rdd.RDD$$anonfun$7.apply(RDD.scala:357)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1165)
	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)
	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)
	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)
	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:357)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:308)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:310)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:123)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
   


    # AglaisPublicExamples/Source counts over the sky
    # ----------------------------------------------------------
   
    [Success]

 
    # AglaisPublicExamples/Mean proper motions over the sky 
    # ----------------------------------------------------------

    [Success]


    # AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier [Failed]
    # ----------------------------------------------------------
 
    [Success]
