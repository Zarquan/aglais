#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#



    Target:

        Create an Aglais Cluster that uses Cinder for tmp storage

    Result:

        Ongoing..



# -------------------------------------------------
# Checkout our branch on stvoutsin/aglais
#[user@desktop]

git checkout issue-288-cinder 


# ---------------------------------
# Update the Openstack cloud name.
#[user@desktop]

    cloudname=gaia-test

    sed -i '
        s/^\(AGLAIS_CLOUD\)=.*$/\1='${cloudname:?}'/
        ' "${HOME}/aglais.env"


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        atolmis/ansible-client:2020.12.02 \
        bash




# -----------------------------------------------------
# Delete everything ....
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}"

	
     >    real	1m56.872s
     >    user	0m25.541s
     >    sys	0m1.862s


# -----------------------------------------------------
# Create evertything ....
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}"

PLAY RECAP **************************************************************************************************************************************************************************************************
master01                   : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
worker01                   : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
worker02                   : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
worker03                   : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
worker04                   : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
zeppelin                   : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

/

     >    real	37m53.135s
     >    user	9m43.436s
     >    sys	2m0.823s




# -----------------------------------------------------
# Zeppelin Service running at:

    http://128.232.227.173:8080/



# -----------------------------------------------------
# Create gaiauser
#[fedora@zeppelin]

    sudo yum install nano
    nano /home/fedora/zeppelin-0.8.2-bin-all/conf/shiro.ini

    # Change password to gaiauser 



# -----------------------------------------------------
# Run a test notebook ..
#[user@zeppelin]

    # Import from URL
    # Good astrometric solutions via ML Random Forrest classifier
    https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2FRPC4BFS/note.json

        Works

        Initial select
        Took 12 min 28 sec. Last updated by admin at March 10 2021, 3:00:12 PM.


        HR diagram
	Took 6 sec. Last updated by admin at March 10 2021, 3:11:54 PM.

        Forrest Classifier
	rf = RandomForestClassifier(featureSubsetStrategy = 'sqrt', featuresCol = 'features', labelCol = 'label', numTrees = 500, impurity = 'gini', seed=42)
	Took 15 min 1 sec. Last updated by admin at March 10 2021, 3:27:26 PM.


        # Rest of Notebook runs Successfully



# -----------------------------------------------------
# Access the Admin UI & Note resource usage
#[user@desktop]

    # Tunnel connection to Master via Zeppelin IP
    
    ssh -L '8088:master01:8088' fedora@128.232.227.173

    firefox http://localhost:8088/cluster &


    # Click the Tracking UI "ApplicationMaster" link of the currently running Application. (All the way to the right of the screen)
    # When clicking the link will direct us to something like: http://master01:8088/proxy/application_1615379044631_0001/
    # Change master01 -> localhost and reload
    # This is the Spark Master UI

    # Check which worker nodes are currently running the app
    # Click "Executors" tab at the top

    # We see 3 active  executors, running on worker01, worker03 & worker04.
    # No disk usage shown so far..


    # Overall it looks like the app has 29GB of memory available in total, 7.3GB per worker (+ 7.3GB on driver node)
    # We also see 4 cores per worker node, for a total of 12 Cores, (0 Cores on driver node)


    # In the Yarn UI (http://localhost:8088/cluster) we see:

    # Overal totals:
    # 4 active nodes, 4 Containers running
    
    # Memory: 
    #   112GB Used
    #   168GB Total
    #   56GB Reserved

    # Cores
    #   4 VCores Used
    #   6 VCores Total


    # Application usage (application_1615379044631_0001)    
    # 4 Containers
    # 4 Allocated CPU Cores
    # 114 GB RAM Allocated 
    # 2 CPU Cores Reserved
    # 57 GB Reserved RAM
    # 66.7 % of Cluster used

# -----------------------------------------------------
# Check tmp storage on Cinder mount (worker01)
#[fedora@worker01]


ls -al /mnt/cinder/vdc/hadoop/temp/
total 0
drwxrwsr-x. 1 fedora fedora 24 Mar 10 12:24 .
drwxrwsr-x. 1 root   root   24 Mar 10 12:13 ..
drwxr-xr-x. 1 fedora fedora 54 Mar 10 13:10 nm-local-dir


# -----------------------------------------------------
# Try Forest Classifier test with full dataset
# Remove the Filter and Change numTrees to "5000"


# With tmp on local storage, this has previously caused the "out of disk space" exceptions

rf = RandomForestClassifier(featureSubsetStrategy = 'sqrt', featuresCol = 'features', labelCol = 'label', numTrees = 5000, impurity = 'gini', seed=42)
Took 2 hrs 31 min 22 sec. Last updated by admin at March 10 2021, 8:15:21 PM.

# Success


