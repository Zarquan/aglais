#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#



    Target:

        Test the latest settings for the tiny-16 deployment

    Result:

        Failed (Sort of)
        ----------------
        ML Notebook caused an out of disk space issue
        5d Kinematic notebook produced an error, but the offending cell (numpy error) was fixed
        Other notebooks were successful

# -----------------------------------------------------
# Checkout the deployment branch.
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"

            git checkout 'issue-463'

    popd


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    AGLAIS_CLOUD=gaia-test

    docker run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        atolmis/ansible-client:2020.12.02 \
        bash


# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}"


     >   Done


# -----------------------------------------------------
# Create everything, using the tiny-16 config.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            'tiny-16'

      >   Done

# -----------------------------------------------------
# Setup integration with github
#[root@ansibler]


  ssh zeppelin \
        '
        export githubuser=user
        export githubpass=pass

        rm -rf /home/fedora/zeppelin-0.8.2-bin-all/notebook
	git clone https://${githubuser:?}:${githubpass:?}@github.com/wfau/aglais-notebooks.git /home/fedora/zeppelin-0.8.2-bin-all/notebook

	cat > "${HOME}/zeppelin-0.8.2-bin-all/notebook/.git/hooks/post-commit" << EOF
	#!/bin/sh
	git push 

	EOF

	chmod +x ${HOME}/zeppelin-0.8.2-bin-all/notebook/.git/hooks/post-commit
	/home/fedora/zeppelin-0.8.2-bin-all/bin/zeppelin-daemon.sh restart
	'

	> Cloning into '/home/fedora/zeppelin-0.8.2-bin-all/notebook'...
	  Zeppelin stop                                              [  OK  ]
	  Zeppelin start                                             [  OK  ]

	# Success



# -----------------------------------------------------
# Login via Firefox
#[user@desktop]

    firefox --new-window "http://128.232.227.137:8080/" &



# -----------------------------------------------------
# Run a set of known Notebooks for validation
# -----------------------------------------------------


    # Library Validation:
    # https://raw.githubusercontent.com/wfau/aglais-testing/main/notebooks/Library%20validation.json
  
    [Success] 



    # AglaisPublicExamples/Set Up
    # ----------------------------------------------------------
 
    # Change the Catalogue Setup tp:

	%pyspark

	# database name to create
	database = "gaiaedr3"

	# root data store path: TODO change this to the official one when established.
	data_store = "file://///data/gaia/GEDR3_2048/"

	# create the database and switch the current SQL database context to it (from default)
	spark.sql("create database " + database)
	spark.sql("use " + database)

	# create the tables against their corresponding file sets and schema
	reattachParquetFileResourceToSparkContext("gaia_source", data_store + "GEDR3_GAIASOURCE", gaia_source_schema)
	reattachParquetFileResourceToSparkContext("gaia_source_tmasspsc_best_neighbours", data_store + "GEDR3_2048_2MASSPSC_BEST_NEIGHBOURS", tmasspscxsc_best_neighbour_schema, twomass_psc_schema)
	reattachParquetFileResourceToSparkContext("gaia_source_allwise_best_neighbours", data_store + "GEDR3_ALLWISE_BEST_NEIGHBOURS", allwise_best_neighbour_schema, twomass_psc_schema)
        reattachParquetFileResourceToSparkContext("gaia_source_ps1_best_neighbours", data_store + "GEDR3_2MASSPSC_BEST_NEIGHBOURS", panstarrs1_best_neighbour_schema, panstarrs_dr1_otmo_schema)
 
    [Success]


    # AglaisPublicExamples/Data Holdings 
    # ----------------------------------------------------------
 
    [Success]


    # AglaisPublicExamples/Source counts over the sky
    # ----------------------------------------------------------
   
    [Success]

 
    # AglaisPublicExamples/Mean proper motions over the sky 
    # ----------------------------------------------------------

    [Success]


    # AglaisPublicExamples/Good astrometric solutions via ML Random Forrest classifier [Failed]
    # ----------------------------------------------------------
    
    # Raw catalogue with selected columns
    > Took 11 min 35 sec. Last updated by admin at May 24 2021, 2:07:04 PM. (outdated)
 
    [Success]

    # Train up the Random Forrest

    > Py4JJavaError: An error occurred while calling o312.fit. : org.apache.spark.SparkException: Job aborted due to stage failure: Task 1948 in stage 55.0 failed 4 times, most recent failure: Lost task 1948.3 in stage 55.0 (TID 53121, worker16, executor 11): java.io.IOException: No space left on device

    [Failed]


    # AglaisPublicExamples/5d kinematic clustering 
    # ----------------------------------------------------------

    # Function definitions 
    # This cell previously fails with error: "numpy.ufunc object has no attribute __module__ Spark"

    # Change first line to: from math import pi, cos, sin
       
    [Success]
    
    # df_lsr_cut = df.select("*").where("udf_lsr_cut(ra, dec, parallax, pmra, pmdec) = 1").cache()

    > Py4JJavaError: An error occurred while calling o166.count.
: org.apache.spark.SparkException: Job 6 cancelled because SparkContext was shut down




    # Next: Create a 4 node medium cluster and try again..
