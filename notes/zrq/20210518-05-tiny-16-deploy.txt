#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#


    Target:

        Test the CephFS shares using a custom small-08 deployment

    Result:

        Success, of a kind.
        Still hitting resource limits, had to downsize from small-08 to small-06.
        RandomForest completed in 31min.


# -----------------------------------------------------
# Checkout the target branch.
#[user@desktop]

    source "${HOME:?}/aglais.env"
    pushd "${AGLAIS_CODE}"

            git checkout '20210518-zrq-housekeeping'

    popd

    >   Already on '20210518-zrq-housekeeping'
    >   Your branch is up to date with 'origin/20210518-zrq-housekeeping'.


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    AGLAIS_CLOUD=gaia-dev

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        atolmis/ansible-client:2020.12.02 \
        bash


# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    time \
        /deployments/openstack/bin/delete-all.sh \
            "${cloudname:?}"

    >   real    3m55.058s
    >   user    1m25.109s
    >   sys     0m12.004s


# -----------------------------------------------------
# Create everything, using a custom config.
#[root@ansibler]

    time \
        /deployments/hadoop-yarn/bin/create-all.sh \
            "${cloudname:?}" \
            'tiny-16'

    >   ....
    >   ....


# -----------------------------------------------------
# Check the deployment status.
#[root@ansibler]

    cat '/tmp/aglais-status.yml'

    >   ....
    >   ....


# -----------------------------------------------------
# Add the Zeppelin user accounts.
#[root@ansibler]

    ssh zeppelin

        pushd "${HOME}/zeppelin-0.8.2-bin-all"

            # Manual edit to add names and passwords
            vi conf/shiro.ini

            # Restart Zeppelin for the changes to take.
            ./bin/zeppelin-daemon.sh restart

        popd
    exit

    >   ....
    >   ....


# -----------------------------------------------------
# Get the public IP address of our Zeppelin node.
#[root@ansibler]

    deployname=$(
        yq read \
            '/tmp/aglais-status.yml' \
                'aglais.status.deployment.name'
        )

    zeppelinid=$(
        openstack \
            --os-cloud "${cloudname:?}" \
            server list \
                --format json \
        | jq -r '.[] | select(.Name == "'${deployname:?}'-zeppelin") | .ID'
        )

    zeppelinip=$(
        openstack \
            --os-cloud "${cloudname:?}" \
            server show \
                --format json \
                "${zeppelinid:?}" \
        | jq -r '.addresses' \
        | sed '
            s/[[:space:]]//
            s/.*=\(.*\)/\1/
            s/.*,\(.*\)/\1/
            '
        )

cat << EOF
Zeppelin ID [${zeppelinid:?}]
Zeppelin IP [${zeppelinip:?}]
EOF

    >   ....
    >   ....


# -----------------------------------------------------
# Update our DNS entries.
#[root@ansibler]

    ssh root@infra-ops.aglais.uk

        vi /var/aglais/dnsmasq/hosts/gaia-dev.hosts

        ~   128.232.227.174  zeppelin.gaia-dev.aglais.uk


        podman kill --signal SIGHUP dnsmasq

        podman logs dnsmasq | tail

        exit

    >   ....
    >   ....



# -----------------------------------------------------
# -----------------------------------------------------
# Login via Firefox
#[user@desktop]

    firefox --new-window "http://zeppelin.gaia-dev.aglais.uk:8080/" &


# -----------------------------------------------------
# -----------------------------------------------------

    Run the test againts the new data ....

    Good astrometric solutions via ML Random Forest classifier
    https://raw.githubusercontent.com/wfau/aglais-notebooks/main/2FRPC4BFS/note.json

        #
        # Change the column name.
        astrometric_features = [
            ....
            'astrometric_sigma5d_max',
            ....
            ]

        #
        # Use the 8192 partition data.
        gs_parquet = sqlContext.read.parquet('file:////data/gaia/GEDR3_8192/GEDR3_GAIASOURCE')

        #
        # Starting a new test, (500 trees on 100% data)
        #

        First cell - ....
        Last cell  - ....

        ....


        #
        # Use the 4096 partition data.
        gs_parquet = sqlContext.read.parquet('file:////data/gaia/GEDR3_4096/GEDR3_GAIASOURCE')

        #
        # Starting a new test, (500 trees on 100% data)
        #

        First cell - ....
        Last cell  - ....

        ....


        #
        # Use the 2048 partition data.
        gs_parquet = sqlContext.read.parquet('file:////data/gaia/GEDR3_2048/GEDR3_GAIASOURCE')

        #
        # Starting a new test, (500 trees on 100% data)
        #

        First cell - ....
        Last cell  - ....

        ....






    # Checksum timing during the run

    >   ....
    >   ....

