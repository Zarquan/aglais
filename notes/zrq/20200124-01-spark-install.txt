#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#

    The reason for doing this is we need a Spark deployment with an up to date version of Hadoop.
    The binary releases of Spark include an old version of Hadoop, that have a very old version of the S3 jars.
    We need a more recent version of the S3 coponents to be able to access data in the OpenStack Swift system.

    Plan is to have separate installs of (Hadoop) and (Spark without Haddop), and then point Spark at the
    Hadoop libraies.

    https://stackoverflow.com/questions/28664834/which-cluster-type-should-i-choose-for-spark/34657719#34657719
    https://stackoverflow.com/questions/32022334/can-apache-spark-run-without-hadoop

    https://spark.apache.org/docs/latest/hadoop-provided.html
    https://spark.apache.org/docs/latest/

    There are some issues with S3 to be aware of (2015):
    https://arnon.me/2015/08/spark-parquet-s3/

    This also provides a step towards ditching YARN and using Kubernetes instead.
    https://spark.apache.org/docs/latest/running-on-kubernetes.html


    Plan

    Install Java
    Install Hadoop
    Install Spark without Hadoop
    Configure SPark to use Hadoop

    Note - at the moment our worker nodes have no storage



# -----------------------------------------------------
# Create our cloud config file.
#[user@desktop]

    #
    # See 20200114-03-podman-volume.txt
    #

# -----------------------------------------------------
# Allow podman container to use the SSH authentication socket on our desktop.
# https://osric.com/chris/accidental-developer/2017/11/selinux-audit2why-audit2allow-policy-files/
# https://stackoverflow.com/a/52326925
#[user@desktop]

    #
    # See 20200222-01-ansible-deploy.txt
    #

# -----------------------------------------------------
# Create a container to work with.
# https://podman.readthedocs.io/en/latest/markdown/podman-run.1.html
#[user@desktop]

    source "${HOME}/aglais.settings"

    podman run \
        --rm \
        --tty \
        --interactive \
        --hostname ansibler \
        --env SSH_AUTH_SOCK=/mnt/ssh_auth_sock \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/experiments/zrq/ansible:/mnt/ansible:ro,z" \
        atolmis/ansible-client:latest \
        bash


# -----------------------------------------------------
# Create our Ansible include vars file.
#[root@ansibler]

    cat > /tmp/ansible-vars.yml << EOF

buildtag:  'aglais-$(date '+%Y%m%d')'
cloudname: 'gaia-prod'

EOF


# -----------------------------------------------------
# Run our playbooks from the /mnt/ansible directory.
# Needed to pick up the 'ansible.cfg' config file.
# https://docs.ansible.com/ansible/latest/reference_appendices/config.html#the-configuration-file
#[root@ansibler]

    cd /mnt/ansible


# -----------------------------------------------------
# Create our gateway, master and worker instances.
#[root@ansibler]

    ansible-playbook \
        --inventory "hosts.yml" \
        "combined-01.yml"

--START--
....
....
PLAY RECAP **********************************************************************************************************************************************************************************************************************************
gateway                    : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
localhost                  : ok=32   changed=25   unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
master01                   : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
master02                   : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
worker01                   : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
worker02                   : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
worker03                   : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
worker04                   : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0
--END--


# -----------------------------------------------------
# Install Java on the master and worker nodes.
#[root@ansibler]

    ansible-playbook \
        --inventory "hosts.yml" \
        "10-install-java.yml"





