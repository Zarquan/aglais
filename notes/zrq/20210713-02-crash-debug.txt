#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2021, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#zrq-notes-zeppelin
#

# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman rm ansibler

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --publish 3000:3000 \
        --publish 8088:8088 \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/deployments:/deployments:ro,z" \
        atolmis/ansible-client:2020.12.02 \
        bash


# -----------------------------------------------------
# Set the target cloud.
#[root@ansibler]

    cloudname=gaia-prod


# -----------------------------------------------------
# Create the deployment status.
#[root@ansibler]

    cat > '/tmp/aglais-status.yml' << EOF
aglais:
 status:
   deployment:
     type: hadoop-yarn
     conf: cclake-medium-04
     name: gaia-prod-20210623
     date: 20210623T114559
 spec:
   openstack:
     cloud: gaia-prod
EOF


    ln -sf '/tmp/aglais-status.yml' '/tmp/ansible-vars.yml'


# -----------------------------------------------------
# Run the ssh config script.
#[root@ansibler]

    config=cclake-medium-04
    inventory="config/${config:?}.yml"

    pushd "/deployments/hadoop-yarn/ansible"

        ansible-playbook \
            --verbose \
            --verbose \
            --inventory "${inventory:?}" \
            "05-config-ssh.yml"

        ansible-playbook \
            --verbose \
            --verbose \
            --inventory "${inventory:?}" \
            "08-ping-test.yml"

    popd


# -----------------------------------------------------
# Tunnel connection to Grafana on the monitor node.
# https://linuxize.com/post/how-to-setup-ssh-tunneling/
#[root@ansibler]

    ssh -f -N -L '3000:monitor:3000' fedora@zeppelin


# -----------------------------------------------------
# -----------------------------------------------------
# Open Grafana in Firefox
#[user@desktop]

    firefox --new-window 'http://localhost:3000/login' &


# -----------------------------------------------------
# Add a new Data Source
# From Stelios's notes

    # Click on button "Data Sources: Add your first data source"
    # Select Prometheus as the Data source
    # Set the url to: http://monitor:9090
    # Set the Scrape interval to 5s


# -----------------------------------------------------
# Add a new Dashboard
# From Stelios's notes

    # Import Dashboards for Node Exporter metrics:
    # https://grafana.com/grafana/dashboards/11074

    # Import our own dashboards from github.
    # Import from copy/paste JSON.
    # Import from filesystems on monitor host.
    # Install own dashboards from github.


# -----------------------------------------------------
# -----------------------------------------------------
# Tunnel connection to the Spark UI on the master node.
# https://linuxize.com/post/how-to-setup-ssh-tunneling/
#[root@ansibler]

    ssh -f -N -L '8088:master01:8088' fedora@zeppelin


# -----------------------------------------------------
# -----------------------------------------------------
# Login via Firefox
#[user@desktop]

    firefox --new-window "http://localhost:8088/" &

    # Entry point for Hadoop cluster
    http://localhost:8088/cluster

    # Fixed hostname in URL for Spark Application
    http://master01:8088/proxy/application_1625714931998_0002/

    # Modified hostname for Spark Application to use the proxy.
    http://localhost:8088/proxy/application_1625714931998_0002/





    ssh -f -N \
        -L '3000:monitor:3000'  \
        -L '8088:master01:8088' \
        fedora@zeppelin

