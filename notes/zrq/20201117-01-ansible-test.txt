#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#zrq-notes-time
#zrq-notes-indent
#zrq-notes-crypto
#zrq-notes-ansible
#zrq-notes-osformat
#

    Target:

        Run the initial Ansible deploy

    Result:

        Works


# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME:?}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --name ansibler \
        --hostname ansibler \
        --env "SSH_AUTH_SOCK=/mnt/ssh_auth_sock" \
        --volume "${SSH_AUTH_SOCK}:/mnt/ssh_auth_sock:rw,z" \
        --env "clouduser=${AGLAIS_USER:?}" \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --volume "${HOME:?}/clouds.yaml:/etc/openstack/clouds.yaml:ro,z" \
        --volume "${AGLAIS_CODE:?}/experiments/openstack:/openstack:ro,z" \
        --volume "${AGLAIS_CODE:?}/experiments/hadoop-yarn:/hadoop-yarn:ro,z" \
        atolmis/ansible-client:latest \
        bash

# -----------------------------------------------------
# Delete everything.
#[root@ansibler]

    /openstack/bin/delete-all.sh


# -----------------------------------------------------
# Run the main Ansible deployment.
#[root@ansibler]

    /hadoop-yarn/bin/create-all.sh


# -----------------------------------------------------
# Run a PySpark example ....
# https://www.tutorialspoint.com/pyspark/pyspark_sparkcontext.htm
#[root@ansibler]

    ssh master01

        pyspark


    >   Python 3.7.3 (default, Mar 27 2019, 13:36:35)
    >   [GCC 9.0.1 20190227 (Red Hat 9.0.1-0.8)] on linux
    >   Type "help", "copyright", "credits" or "license" for more information.
    >   2020-11-17 04:45:46,523 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
    >   Setting default log level to "WARN".
    >   To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
    >   ....
    >   ....

    #
    # Hangs ... :-(
    # Something to do with this version of Spark ?
    #




import random

limit = 1000000

def inside(p):
    x, y = random.random(), random.random()
    return x*x + y*y < 1

count = sc.parallelize(
    xrange(0, limit)
    ).filter(
        inside
        ).count()

print "Pi is roughly %f" % (4.0 * (count / limit))





# -----------------------------------------------------
# Create the Manila router.
#[root@ansibler]

    ....

# -----------------------------------------------------
# Mount the Gaia DR2 data.
#[root@ansibler]

    /hadoop-yarn/bin/cephfs-mount.sh \
        "${cloudname:?}" \
        'aglais-gaia-dr2' \
        '/data/gaia/dr2'









