#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

    #
    # Looking at the ratio of memory to cpu resources.
    #

# -----------------------------------------------------
# Create a container to work with.
#[user@desktop]

    source "${HOME}/aglais.env"

    podman run \
        --rm \
        --tty \
        --interactive \
        --hostname openstacker \
        --env "cloudname=${AGLAIS_CLOUD:?}" \
        --env "clustername=${CLUSTER_NAME:?}" \
        --volume "${HOME}/clouds.yaml:/etc/openstack/clouds.yaml:z" \
        atolmis/openstack-client \
        bash


# -----------------------------------------------------
# List the available flavors.
#[user@kubernator]

    openstack \
        --os-cloud "${cloudname:?}" \
        flavor list

    >   +--------------------------------------+-------------------+--------+------+-----------+-------+-----------+
    >   | ID                                   | Name              |    RAM | Disk | Ephemeral | VCPUs | Is Public |
    >   +--------------------------------------+-------------------+--------+------+-----------+-------+-----------+
    >   | 20061eba-9e88-494c-95a3-41ed77721244 | general.v1.small  |  22528 |   20 |         0 |     6 | True      |
    >   | 406a17e0-afd0-47d3-a6ad-8b19198bdd97 | general.v1.tiny   |   6144 |   12 |         0 |     2 | True      |
    >   | 8a821ef8-20b8-4bbb-990b-91198745e7a7 | general.v1.xlarge | 184320 |   20 |       340 |    28 | True      |
    >   | 996c1c8c-c934-411c-9631-b74eb2829631 | general.v1.medium |  46080 |   20 |        60 |    14 | True      |
    >   | c4c07f5a-260a-4f22-9530-a09a19aa490a | general.v1.large  |  92160 |   20 |       160 |    28 | True      |
    >   +--------------------------------------+-------------------+--------+------+-----------+-------+-----------+


# -----------------------------------------------------
# List the memory:cpucore ratio.
#[user@kubernator]

    openstack \
        --os-cloud "${cloudname:?}" \
        flavor list \
            --format json \
    | jq 'sort_by(.VCPUs) | .[] | { name: .Name, ratio: (.RAM / (.VCPUs * 1024)) }'

    >   {
    >     "name": "general.v1.tiny",
    >     "ratio": 3
    >   }
    >   {
    >     "name": "general.v1.small",
    >     "ratio": 3.6666666666666665
    >   }
    >   {
    >     "name": "general.v1.medium",
    >     "ratio": 3.2142857142857144
    >   }
    >   {
    >     "name": "general.v1.xlarge",
    >     "ratio": 6.428571428571429
    >   }
    >   {
    >     "name": "general.v1.large",
    >     "ratio": 3.2142857142857144
    >   }

    #
    # Most flavors have a ratio of around 3.
    # The xlarge flavor gives us a larger ratio of 6.
    #

    #
    # Experiment - can we create a cluster with a mixture of node sizes.
    # Experiment - can we manually add nodes to a cluster.
    #

    #
    # If we have a few large or xlarge nodes, then prioritse those for the Zeppelin or interpreters ?
    # What happens to data exchanged between cells ?
    # How much load does the main Zeppelin node get ?
    #

    #
    # Is it as simple as adding and running 'kubeadm join' ?
    # Do we need to add other things too ?
    #

    #
    # Scalable JupyterHub deployment on bare-metal Kubernetes
    # https://indico.in2p3.fr/event/21938/
    # https://github.com/rohinijoshi06/jupyterhub-on-k8s

    # Not bare metal - using Ubuntu VMs in Openstack.
    # Using NFS provisioner, which stores data on the VMs,
    # so presumably re-publishing Cinder volumes.
    #


    #
    # Weave Sope looks interesting.
    # https://www.weave.works/docs/scope/latest/features/










