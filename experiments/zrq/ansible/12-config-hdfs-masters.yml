#
# <meta:header>
#   <meta:licence>
#     Copyright (c) 2020, ROE (http://www.roe.ac.uk/)
#
#     This information is free software: you can redistribute it and/or modify
#     it under the terms of the GNU General Public License as published by
#     the Free Software Foundation, either version 3 of the License, or
#     (at your option) any later version.
#
#     This information is distributed in the hope that it will be useful,
#     but WITHOUT ANY WARRANTY; without even the implied warranty of
#     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#     GNU General Public License for more details.
#
#     You should have received a copy of the GNU General Public License
#     along with this program.  If not, see <http://www.gnu.org/licenses/>.
#   </meta:licence>
# </meta:header>
#
#

- name: "Configure Hadoop masters"
  hosts: masters
  gather_facts: false
  vars:
    hdname: "hadoop-3.2.1"
    hdbase: "/opt"
    hdhome: "/opt/hadoop"
    hddata: "/var/local/hadoop"
    hdhost: "{{groups['masters'][0]}}"
    hduser: "{{hostvars[inventory_hostname].login}}"

  tasks:

    - name: "Create [{{hddata}}/namenode/fsimage]"
      become: true
      file:
        path: "{{hddata}}/namenode/fsimage"
        mode: 'u=rwx,g=rwxs,o=rx'
        state: directory
        recurse: yes
        owner: "{{hduser}}"
        group: "{{hduser}}"

    # TODO - deprecated, remove next iteration
    - name: "Create [{{hddata}}/namenode/data]"
      become: true
      file:
        path: "{{hddata}}/namenode/data"
        mode: 'u=rwx,g=rwxs,o=rx'
        state: directory
        owner: "{{hduser}}"
        group: "{{hduser}}"

    # https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-common/ClusterSetup.html#Configuring_the_Hadoop_Daemons
    # https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-common/core-default.html
    - name: "Configure [{{hdhome}}/etc/hadoop/core-site.xml]"
      become: true
      blockinfile:
        path:   "{{hdhome}}/etc/hadoop/core-site.xml"
        marker: "<!-- {mark} Ansible managed filesystem URL -->"
        insertbefore: "</configuration>"
        block: |
          <property>
            <!--+
                | The name of the default file system.
                | A URI whose scheme and authority determine the FileSystem implementation.
                | The uri's scheme determines the config property (fs.SCHEME.impl) naming the FileSystem implementation class.
                | The uri's authority is used to determine the host, port, etc. for a filesystem.
                | https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-common/core-default.html
                |
                | 'fs.defaultFS' replaces the deprecated property 'fs.default.name'.
                | https://stackoverflow.com/a/30480984
                | http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/DeprecatedProperties.html
                +-->
            <name>fs.defaultFS</name>
            <value>hdfs://{{hdhost}}:9000</value>
          </property>

    # https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-common/ClusterSetup.html#Configuring_the_Hadoop_Daemons
    # https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
    - name: "Configure [{{hdhome}}/etc/hadoop/hdfs-site.xml]"
      become: true
      blockinfile:
        path:   "{{hdhome}}/etc/hadoop/hdfs-site.xml"
        marker: "<!-- {mark} Ansible managed HDFS master config -->"
        insertbefore: "</configuration>"
        block: |
          <property>
            <!--+
                | Determines where on the local filesystem the DFS name node should store the name table(fsimage).
                | If this is a comma-delimited list of directories then the name table is replicated in all of the directories, for redundancy. 
                | https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
                +-->
            <name>dfs.namenode.name.dir</name>
            <value>{{hddata}}/namenode/fsimage</value>
          </property>
          <property>
            <!--+
                | Names a file that contains a list of hosts that are permitted to connect to the namenode.
                | The full pathname of the file must be specified. If the value is empty, all hosts are permitted.
                | https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
                +-->
            <name>dfs.hosts</name>
            <value/>
          </property>
          <property>
            <!--+
                | Names a file that contains a list of hosts that are not permitted to connect to the namenode.
                | The full pathname of the file must be specified. If the value is empty, no hosts are excluded.
                | https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
                +-->
            <name>dfs.hosts.exclude</name>
            <value/>
          </property>
          <property>
            <!--+
                | Default block replication.
                | The actual number of replications can be specified when the file is created.
                | The default is used if replication is not specified in create time.           
                | https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
                +-->
            <name>dfs.replication</name>
            <value>2</value>
          </property>
          <property>
            <!--+
                | Reserved space calculator.
                | https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
                +-->
            <name>dfs.datanode.du.reserved.calculator</name>
            <value>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ReservedSpaceCalculator$ReservedSpaceCalculatorPercentage</value>
          </property>
          <property>
            <!--+
                | Reserved space percentage.
                | https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
                +-->
            <name>dfs.datanode.du.reserved.pct</name>
            <value>10</value>
          </property>

    # https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-common/ClusterSetup.html#Slaves_File
    - name: "Create [/etc/hadoop/workers]"
      become: true
      template:
        src:  "templates/hadoop-workers.j2"
        dest: "{{hdhome}}/etc/hadoop/workers"


